# Task_w3: Web Scraping and EDA

## 📌 Overview
This project demonstrates a complete workflow starting from **web scraping** data, saving it locally, and then performing **data cleaning** and **exploratory data analysis (EDA)**.

The repository contains two main Jupyter notebooks:
1. `scraped_data.ipynb` → Responsible for scraping raw data from the source website(s).
2. `EDA.ipynb` → Focused on cleaning the scraped dataset and performing exploratory analysis to understand patterns and insights.

---

## ⚙️ Requirements
- Python 3.x
- Jupyter Notebook
- Common libraries: `pandas`, `numpy`, `matplotlib`, `seaborn`, `requests`, `beautifulsoup4` (depending on scraping method)

Install dependencies:
```bash
pip install -r requirements.txt


Task_w3/
│
├── scraped_data.ipynb   # Web scraping and saving raw dataset
├── EDA.ipynb            # Data cleaning and exploratory data analysis
├── requirements.txt     # List of dependencies
└── README.md            # Project documentation


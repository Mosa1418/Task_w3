# Task_w3: Web Scraping and EDA

## ğŸ“Œ Overview
This project demonstrates a complete workflow starting from **web scraping** data, saving it locally, and then performing **data cleaning** and **exploratory data analysis (EDA)**.

The repository contains two main Jupyter notebooks:
1. `scraped_data.ipynb` â†’ Responsible for scraping raw data from the source website(s).
2. `EDA.ipynb` â†’ Focused on cleaning the scraped dataset and performing exploratory analysis to understand patterns and insights.

---

## âš™ï¸ Requirements
- Python 3.x
- Jupyter Notebook
- Common libraries: `pandas`, `numpy`, `matplotlib`, `seaborn`, `requests`, `beautifulsoup4` (depending on scraping method)

Install dependencies:
```bash
pip install -r requirements.txt


Task_w3/
â”‚
â”œâ”€â”€ scraped_data.ipynb   # Web scraping and saving raw dataset
â”œâ”€â”€ EDA.ipynb            # Data cleaning and exploratory data analysis
â”œâ”€â”€ requirements.txt     # List of dependencies
â””â”€â”€ README.md            # Project documentation

